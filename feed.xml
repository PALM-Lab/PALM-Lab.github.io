<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2025-12-03T12:07:27+00:00</updated><id>/feed.xml</id><title type="html">PALM LAB</title><subtitle>A cognitive neuroscience lab studying attention and working memory.</subtitle><entry><title type="html">Multivariate classification shows associative learning reduces working memory load</title><link href="/2025/11/26/acns2025.html" rel="alternate" type="text/html" title="Multivariate classification shows associative learning reduces working memory load" /><published>2025-11-26T00:00:00+00:00</published><updated>2025-12-03T12:06:21+00:00</updated><id>/2025/11/26/acns2025</id><content type="html" xml:base="/2025/11/26/acns2025.html"><![CDATA[<p>Talk presentation by William Ngiam at the Australasian Cognitive Neuroscience Society 2025 conference. This was part of a symposium titled “A model collaboration” encouraging connection between mathematical psychology and cognitive neuroscience.</p>

<h3 id="abstract">Abstract</h3>

<p>The amount of information that can be maintained in mind – or working memory capacity – is sharply limited. Longstanding debate about the nature of this capacity limit stems from disagreement on the representational ‘unit’ of working memory’; some argue for an item-based limit, whereas others argue for resource-based limits. A recent trend amongst cognitive neuroscientists is to use machine learning with neuroimaging data to decode the contents of working memory. But what is being decoded? We should not rely on simply using a “working memory task” to declare we are decoding working memory. Without a reliable theory or formal model constraining what a working memory representation is and is not, interpretation will be very difficult. I will argue that the complexity of modelling working memory is unappreciated – that there is a plurality of viable models. I will present one formal model of working memory recall in the whole-report task (Ngiam et al., 2024), which dovetails with recent successful decoding of itembased load in working memory (Thyer et al., 2022). I will then show recent empirical work exploring how this multivariate signature of item-based load changes with associative learning. The key result is that decoding differs between subjects who show explicit learning and those who do not. Learners show a reduction in item-based load (in line with ‘chunking’), but multidimensional scaling reveals this reduction is not straightforwardly explained with pure item-based models. Thus, I hope to demonstrate that progress can be made with careful iteration between formal modelling and neuroimaging.</p>

<h3 id="slides">Slides</h3>

<object data="https://palm-lab.github.io/files/Ngiam_ACNS2025.pdf" type="application/pdf" width="100%" height="800px">
    <embed src="https://palm-lab.github.io/files/Ngiam_ACNS2025.pdf" />
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://palm-lab.github.io/files/Ngiam_ACNS2025.pdf">View as PDF</a>.</p>
    &lt;/embed&gt;
</object>
<p><u><a href="https://palm-lab.github.io/files/Ngiam_ACNS2025.pdf">Download PDF</a></u><br /></p>]]></content><author><name>william-ngiam</name></author><category term="ACNS" /><category term="talk" /><category term="representational similarity analysis" /><category term="multivariate decoding" /><category term="cognitive model" /><summary type="html"><![CDATA[Talk presentation by William Ngiam at the Australasian Cognitive Neuroscience Society 2025 conference. This was part of a symposium titled “A model collaboration” encouraging connection between mathematical psychology and cognitive neuroscience.]]></summary></entry><entry><title type="html">Modelling the psychological representation underlying perceptual and cognitive tasks</title><link href="/2025/11/25/aspp2025.html" rel="alternate" type="text/html" title="Modelling the psychological representation underlying perceptual and cognitive tasks" /><published>2025-11-25T00:00:00+00:00</published><updated>2025-12-03T12:06:21+00:00</updated><id>/2025/11/25/aspp2025</id><content type="html" xml:base="/2025/11/25/aspp2025.html"><![CDATA[<p>Talk presentation by William Ngiam at the Australasian Society for Philosophy and Psychology 2025 conference.</p>

<h3 id="abstract">Abstract</h3>

<p>Many cognitive models assume a set of processes operating upon a psychological representation. This representation is often derived using multidimensional scaling (MDS) of similarity judgments. While MDS-based models have been useful in exploring cognitive phenomena, the representation itself should not be left unexplained. Further, some take issue with a similarity-based projection as the basis for cognition. This issue has recently emerged in the field of visual working memory (VWM). Most VWM models are constructed on the physical stimulus space (e.g. Neural Resource model; Bays et al., 2014; Interference Model, Oberauer and Lin, 2017), but Schurgin et al. (2020) recently argued for a signal-detection model in terms of psychological similarity. It seems likely that there are both perceptual and psychological contributions to VWM. Thus, there remains a need to be able to model the underlying VWM representation. We took a Bayesian generative modelling approach and modelled open data of three tasks: a perceptual reproduction task, a quad psychophysical scaling task, and a memory reproduction task (Tomic and Bays, 2024). We show that the underlying representation can be sensibly recovered with this approach, finding non-uniformity in the representation across all tasks that is theoretically tractable. We find the recovered representation differs slightly across all tasks, likely due to the task context, which raises some questions for measurement models and theories of VWM.</p>

<h3 id="slides">Slides</h3>

<object data="https://palm-lab.github.io/files/Ngiam_ASPP2025.pdf" type="application/pdf" width="100%" height="800px">
    <embed src="https://palm-lab.github.io/files/Ngiam_ASPP2025.pdf" />
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://palm-lab.github.io/files/Ngiam_ASPP2025.pdf">View as PDF</a>.</p>
    &lt;/embed&gt;
</object>
<p><u><a href="https://palm-lab.github.io/files/Ngiam_ASPP2025.pdf">Download PDF</a></u><br /></p>]]></content><author><name>william-ngiam</name></author><category term="ASPP" /><category term="talk" /><category term="cognitive model" /><category term="working memory" /><category term="perception" /><summary type="html"><![CDATA[Talk presentation by William Ngiam at the Australasian Society for Philosophy and Psychology 2025 conference.]]></summary></entry><entry><title type="html">Associative learning changes multivariate neural signatures of visual working memory</title><link href="/2024/05/21/vss2024-6.html" rel="alternate" type="text/html" title="Associative learning changes multivariate neural signatures of visual working memory" /><published>2024-05-21T00:00:00+00:00</published><updated>2025-12-03T12:06:21+00:00</updated><id>/2024/05/21/vss2024-6</id><content type="html" xml:base="/2024/05/21/vss2024-6.html"><![CDATA[<p>Talk presentation by William Ngiam at VSS 2024 on how training subjects to learn color pairs and color triplets leads to changes in multivariate neural signatures of visual working memory load. We find there is a reduction in working memory load following associative learning, and the introduction of an additional signal that we speculate is the involvement of long-term memory.</p>

<h3 id="abstract">Abstract</h3>

<p>A hallmark of visual working memory is its sharp capacity limit, though this limit can be circumvented using learned knowledge. For example, when arrays of to-be-remembered items contain statistical regularities, people can learn the associations between items and recall more information overall (Brady et al., 2009; Ngiam et al., 2019). One proposed mechanism for how this recall benefit is achieved is through ‘memory compression’ – redundancies introduce a reduction of information per item, enabling more items to be stored online. Another proposed mechanism is that pointers are efficiently allocated to each ‘chunk’ with the benefit coming from long-term memory retrieval rather than changes to working memory itself. In an attempt to distinguish between these possibilities, we turned to an EEG measure that tracks the number of individuated items stored in working memory (mvLoad; Thyer et al., 2022). The memory compression account predicts an overall increase in the number of items stored online, whereas the long-term memory retrieval account predicts a reduction in working memory load. Subjects completed a training session where they learned specific color-color pairs. In a subsequent EEG session, subjects completed a recall task with 2 random colors, 4 random colors, or 2 learned color pairs. mvLoad analysis showed a reduction in working memory load for the 2 learned pairs condition (from 4 towards 2), consistent with the notion that an item-based pointer is assigned to each chunk. Moreover, multidimensional scaling shows an additional independent signal that distinguishes the 2 learned pairs condition from the other conditions. We propose that this additional signal reflects the involvement of long-term memory, consistent with the notion that the learned association is being relied upon to maintain the information.</p>

<h3 id="talk-recording">Talk Recording</h3>

<iframe width="560" height="315" src="https://www.youtube.com/embed/ZKJ9IuPL-WY?si=6WBA83CDq39lq8Z8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<h3 id="slides">Slides</h3>

<object data="https://palm-lab.github.io/files/Ngiam_VSS2024.pdf" type="application/pdf" width="100%" height="800px">
    <embed src="https://palm-lab.github.io/files/Ngiam_VSS2024.pdf" />
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://palm-lab.github.io/files/Ngiam_VSS2024.pdf">View as PDF</a>.</p>
    &lt;/embed&gt;
</object>
<p><u><a href="https://palm-lab.github.io/files/Ngiam_VSS2024.pdf">Download PDF</a></u><br /></p>]]></content><author><name>william-ngiam</name></author><category term="VSS" /><category term="talk" /><category term="long-term memory" /><category term="learning" /><category term="chunking" /><category term="mvLoad" /><summary type="html"><![CDATA[Talk presentation by William Ngiam at VSS 2024 on how training subjects to learn color pairs and color triplets leads to changes in multivariate neural signatures of visual working memory load. We find there is a reduction in working memory load following associative learning, and the introduction of an additional signal that we speculate is the involvement of long-term memory.]]></summary></entry><entry><title type="html">Spatiotemporal processing drives contralateral delay activity in a dual working memory and attentional tracking task</title><link href="/2024/05/19/vss2024-5.html" rel="alternate" type="text/html" title="Spatiotemporal processing drives contralateral delay activity in a dual working memory and attentional tracking task" /><published>2024-05-19T00:00:00+00:00</published><updated>2025-12-03T12:06:21+00:00</updated><id>/2024/05/19/vss2024-5</id><content type="html" xml:base="/2024/05/19/vss2024-5.html"><![CDATA[<p>Talk presentation by Piotr Styrkowiec at VSS 2024 on our novel attentional tracking and working memory task – a hybrid of multiple-object tracking and multiple-identity tracking. We look at the contralateral delay activity, an event-related potential component known to track visual working memory load during the task, and find that it seems to track the number of discs to remember rather than the number of colors that need to be remembered.</p>

<h3 id="abstract">Abstract</h3>

<p>Recent work has suggested that storage in visual working memory (VWM) occurs through the assignment of spatiotemporal pointers to the to-be-remembered items (Thyer et al., 2022). Thus, VWM capacity limits may not be set by the stimulus content exactly, but rather by attentional processes that define the spatiotemporal pointers for item-based storage. We examined whether this is the case in the contralateral delay activity (CDA), an event-related potential long known to track VWM load. The CDA has been shown to track the number of targets in multiple-object tracking (Drew and Vogel, 2008), but also the number of to-be-remembered colors (Vogel and Machizawa, 2004). To directly contrast the effects of attentional tracking load and stimulus content load on working memory, we developed a novel dual-task paradigm. Participants track either one or two moving discs (attentional tracking load), with either two or four colors displayed across each of the discs (working memory load). Participants completed a ‘tracking only’ condition, where they would need to monitor the moving target discs like in a multiple-object tracking task, and a ‘tracking plus memory’ condition, where they would track the discs and remember all displayed colors like in a multiple-identity tracking task. The key question was whether or not CDA amplitude would be determined by the number of individuated items tracked, or by the number of distinct colors associated with the currently tracked items. Strikingly, CDA amplitude was determined almost entirely by the number of items tracked, with no reliable effect of variations in the number of colors per tracked item. These findings suggest the CDA largely reflects the maintenance of spatiotemporal pointers for moving objects, not the number of feature values associated with those objects.</p>

<h3 id="talk-recording">Talk Recording</h3>

<iframe width="560" height="315" src="https://www.youtube.com/embed/vwkUzcm_-Eo?si=DkrDpdvk1lFKWtad" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<h3 id="slides">Slides</h3>

<object data="https://palm-lab.github.io/files/Styrkowiec_VSS2024.pdf" type="application/pdf" width="100%" height="800px">
    <embed src="https://palm-lab.github.io/files/Styrkowiec_VSS2024.pdf" />
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://palm-lab.github.io/files/Styrkowiec_VSS2024.pdf">View as PDF</a>.</p>
    &lt;/embed&gt;
</object>
<p><u><a href="https://palm-lab.github.io/files/Styrkowiec_VSS2024.pdf">Download PDF</a></u><br /></p>]]></content><author><name>piotr-styrkowiec</name></author><category term="VSS" /><category term="talk" /><category term="multiple-object tracking" /><category term="EEG" /><category term="contralateral delay activity" /><summary type="html"><![CDATA[Talk presentation by Piotr Styrkowiec at VSS 2024 on our novel attentional tracking and working memory task – a hybrid of multiple-object tracking and multiple-identity tracking. We look at the contralateral delay activity, an event-related potential component known to track visual working memory load during the task, and find that it seems to track the number of discs to remember rather than the number of colors that need to be remembered.]]></summary></entry><entry><title type="html">Associative learning changes multivariate neural signatures of working memory load</title><link href="/2023/11/16/opam2023-4.html" rel="alternate" type="text/html" title="Associative learning changes multivariate neural signatures of working memory load" /><published>2023-11-16T00:00:00+00:00</published><updated>2025-12-03T12:06:21+00:00</updated><id>/2023/11/16/opam2023-4</id><content type="html" xml:base="/2023/11/16/opam2023-4.html"><![CDATA[<p>A conference poster presented by William Ngiam at OPAM 2023 showing training to learn color pairs changes neural signatures of working memory load.</p>

<object data="https://palm-lab.github.io/images/posters/OPAM2023.pdf" type="application/pdf" width="100%" height="800px">
    <embed src="https://palm-lab.github.io/images/posters/OPAM2023.pdf" />
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://palm-lab.github.io/images/posters/OPAM2023.pdf">View as PDF</a>.</p>
    &lt;/embed&gt;
</object>
<p><u><a href="https://palm-lab.github.io/images/posters/OPAM2023.pdf">Download PDF</a></u><br /></p>]]></content><author><name>william-ngiam</name></author><category term="opam" /><category term="poster" /><category term="long-term memory" /><category term="mvLoad" /><summary type="html"><![CDATA[A conference poster presented by William Ngiam at OPAM 2023 showing training to learn color pairs changes neural signatures of working memory load.]]></summary></entry><entry><title type="html">Probing working memory pointers by examining contralateral delay activity with moving and updating stimuli</title><link href="/2023/05/19/vss-3.html" rel="alternate" type="text/html" title="Probing working memory pointers by examining contralateral delay activity with moving and updating stimuli" /><published>2023-05-19T00:00:00+00:00</published><updated>2025-12-03T12:06:21+00:00</updated><id>/2023/05/19/vss-3</id><content type="html" xml:base="/2023/05/19/vss-3.html"><![CDATA[<p>A pre-data poster presented by Piotr Styrkowiec and William Ngiam at the Vision Sciences Society Meeting in 2023.</p>

<object data="https://palm-lab.github.io/images/posters/VSS2023.pdf" type="application/pdf" width="100%" height="800px">
    <embed src="https://palm-lab.github.io/images/postersVSS2023.pdf" />
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://palm-lab.github.io/images/posters/VSS2023.pdf">View as PDF</a>.</p>
    &lt;/embed&gt;
</object>
<p><u><a href="https://palm-lab.github.io/images/posters/VSS2023.pdf">Download PDF</a></u><br /></p>]]></content><author><name>piotr-styrkowiec</name></author><category term="vss" /><category term="contralateral delay activity" /><category term="multiple-object tracking" /><summary type="html"><![CDATA[A pre-data poster presented by Piotr Styrkowiec and William Ngiam at the Vision Sciences Society Meeting in 2023.]]></summary></entry><entry><title type="html">Evidence for object-based encoding into visual working memory</title><link href="/2022/05/13/vss2022-2.html" rel="alternate" type="text/html" title="Evidence for object-based encoding into visual working memory" /><published>2022-05-13T00:00:00+00:00</published><updated>2025-12-03T12:06:21+00:00</updated><id>/2022/05/13/vss2022-2</id><content type="html" xml:base="/2022/05/13/vss2022-2.html"><![CDATA[<p>A conference poster presented by William Ngiam at the Vision Sciences Society Meeting in 2022, showing evidence for object-based encoding limits in visual working memory using a novel conjunction whole-report paradigm.</p>

<object data="https://palm-lab.github.io/images/posters/VSS2022.pdf" type="application/pdf" width="100%" height="800px">
    <embed src="https://palm-lab.github.io/images/posters/VSS2022.pdf" />
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://palm-lab.github.io/images/posters/VSS2022.pdf">View as PDF</a>.</p>
    &lt;/embed&gt;
</object>
<p><u><a href="https://palm-lab.github.io/images/posters/VSS2022.pdf">Download PDF</a></u><br /></p>]]></content><author><name>william-ngiam</name></author><category term="vss," /><category term="poster," /><category term="whole-report," /><category term="capacity" /><category term="limits," /><category term="pointers" /><summary type="html"><![CDATA[A conference poster presented by William Ngiam at the Vision Sciences Society Meeting in 2022, showing evidence for object-based encoding limits in visual working memory using a novel conjunction whole-report paradigm.]]></summary></entry><entry><title type="html">Memory compression effects in visual working memory are contingent on explicit long-term memory</title><link href="/2019/11/15/pnom-1.html" rel="alternate" type="text/html" title="Memory compression effects in visual working memory are contingent on explicit long-term memory" /><published>2019-11-15T00:00:00+00:00</published><updated>2025-12-03T12:06:21+00:00</updated><id>/2019/11/15/pnom-1</id><content type="html" xml:base="/2019/11/15/pnom-1.html"><![CDATA[<p>A conference poster presented by William Ngiam at the Psychonomics conference in 2019, showing benefits of statistical learning required explicit awareness of the statistical regularities, suggesting a long-term memory account for the benefit.</p>

<object data="https://palm-lab.github.io/images/posters/psychonomics2019.pdf" type="application/pdf" width="100%" height="800px">
    <embed src="https://palm-lab.github.io/images/posters/psychonomics2019.pdf" />
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://palm-lab.github.io/images/posters/psychonomics2019.pdf">View as PDF</a>.</p>
    &lt;/embed&gt;
</object>
<p><u><a href="https://palm-lab.github.io/images/posters/psychonomics2019.pdf">Download PDF</a></u></p>]]></content><author><name>william-ngiam</name></author><category term="long-term" /><category term="memory," /><category term="chunking," /><category term="psychonomics," /><category term="poster" /><summary type="html"><![CDATA[A conference poster presented by William Ngiam at the Psychonomics conference in 2019, showing benefits of statistical learning required explicit awareness of the statistical regularities, suggesting a long-term memory account for the benefit.]]></summary></entry></feed>