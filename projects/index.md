---
title: Projects
nav:
  order: 1
  tooltip: Our research aims
---

{% include section.html %}

We can attend to only a few items at a time, so how and what we keep in mind is very important. In the current digital age, information is readily available at our fingertips, with algorithms designed to keep us glued to our devices and consume endless streams of content. This has lead to the collective feeling that our ability to focus our attention and our ability to discern information from misinformation is getting worse. The PALM Lab hopes to improve understanding of our attention and cognitive systems, so that the world can regain focus on what is needed to meet the important challenges of today.

The PALM Lab studies our visual attention and working memory systems by linking patterns of brain activity to patterns of cognitive behaviour. We conduct experiments with psychophysics and neuroimaging (typically electroencephalography) methods, and use a combination of computational modeling and machine learning to decipher how humans select and keep information in mind for ongoing perception and cognition. Read below for broad descriptions of our current research projects.

{% include section.html %}

# {% include icon.html icon="fa-solid fa-wrench" %} Research Aims

{% include section.html %}

## How are features bound together and stored in visual working memory?

The visual working memory system rapidly pieces together different visual features, such as color and shape, into perceived objects. At the same time, our visual working memory system can focus our attention on relevant items, filtering out irrelevant items and sometimes even irrelevant features! Our research aims to understand how various **perceptual factors** and **cognitive factors** influences working memory representations. In particular, how does featural information become *bound into objects* and stored in working memory, and whether this sets a sharp limit on how much we can hold in mind. 

{% include section.html %}

## How does experience and learning change how we attend to and store information in working memory?

There is a growing appreciation that our previous learning and experience can shape how we encode and represent information in mind. Our long-term memory system can readily shape how we attend to incoming visual information, at surprisingly early stages of visual processing. In particular, we are interested in **how different types of learning** (e.g. recognition training, statistical learning, associative learning) **may improve the efficiency of the visual working memory system**, whether this is achieved by changing working memory itself or circumventing its sharp capacity limit through other means.

{% include section.html %}

## Decoding the contents of visual working memory using neuroimaging and multivariate classification

A recently developed decoder that applies machine learning classification to neuroimaging (EEG) data (called 'mvLoad') has located a multivariate neural signal that tracks working memory load (i.e. how many items are being stored in visual memory). This gives us an unprecedented window into the processes that underlie visual working memory in conjunction with how the brain actively maintains information. We measure **electroencephalography (EEG)** while subjects complete attention and working memory tasks that are designed to tap into theorized underlying processes. Then, we apply 'mvLoad' to see whether **we can classify and map the changed contents of working memory**.

{% include section.html %}

<! --  {% include tags.html tags="publication, resource, website" %}

{% include search-info.html %}

{% include section.html %}

## Featured

{% include list.html component="card" data="projects" filters="group: featured" %}

{% include section.html %}

## More

{% include list.html component="card" data="projects" filters="group: " style="small" %}
